{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Best Movies by <a href='https://www.imdb.com/chart/top/'>IMDB</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Link to Github repository <a href=\"https://github.com/DoaaAli11/Best-movies-ETL\">best-movies-ETL</a>\n",
    "<hr/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This project is a practice of Data Engineering specially ETL process using python libraries and web scraping technique.<br>\n",
    "We extracted most 25 best movies from <a href=\"https://www.imdb.com/chart/top/\">IMDB</a> official website with their title, release year, length, kind (type) and rate.<br>\n",
    "In this jupyter notebook I'll explain step by step how I completed this script to achieve the desired result."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Libraries used:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "from bs4 import BeautifulSoup\n",
    "from datetime import datetime, time\n",
    "import requests\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- <b>sqlit3</b>: To start connection and store the data into a sqlite3.\n",
    "- <b>BeautifulSoup</b>: To parse the html page, so we could search in its hirericy.\n",
    "- <b>datetime</b>: To complete log file with the timestamp.\n",
    "- <b>requests</b>: To send a request with the url and get the response and get the content to parse it.\n",
    "- <b>pandas</b>: To store the extracted data in dataframes so we can manipulate it, and to save the data localy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://www.imdb.com/chart/top/'\n",
    "to_json = 'Best_movies.json'\n",
    "to_csv = 'Best_movies.csv'\n",
    "sql_table = 'Best_movies'\n",
    "sql_db = 'Best_movies.db'\n",
    "log_file = 'log.txt'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This the url which we gonna extract the data from it.<br>\n",
    "And we're gonna save the data into json, csv and sqlit3 DB.<br>\n",
    "We will keep track of each process in the log file."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sending requset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def request_page(url):\n",
    "    headers = {\n",
    "        \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/58.0.3029.110 Safari/537.3\"\n",
    "    }\n",
    "\n",
    "    response = requests.get(url, headers=headers)\n",
    "\n",
    "    if response.status_code == 200:\n",
    "        print(\"Request Successeded!\")\n",
    "    else:\n",
    "        print(f\"Failed with status code: {response.status_code}\")\n",
    "\n",
    "    return response\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- We will send a GET request with the specified header as we will set User-Agent as shown to ensure the server to not blocking the request causing error 403 forbidden response."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrap_movies_info(response):\n",
    "    html_hir = BeautifulSoup(response.content, 'html.parser')\n",
    "    li_movies = html_hir.find_all(\n",
    "        'li', class_='ipc-metadata-list-summary-item sc-10233bc-0 TwzGn cli-parent')\n",
    "    movies = [x.find('div').find_next_sibling() for x in li_movies]\n",
    "    movies_info = [x.find('span').find_next_sibling() for x in movies]\n",
    "\n",
    "    df = pd.DataFrame(\n",
    "        columns=['Title', 'Release_Year', 'Length', 'Kind', 'Rate'])\n",
    "\n",
    "    for m in movies_info:\n",
    "        title = m.find('h3').text\n",
    "        info = m.find('div').find_next_sibling().find_all('span')\n",
    "        releae_year = info[0].text\n",
    "        length = info[1].text\n",
    "        kind = info[2].text\n",
    "        rate = m.find('div').find_next_sibling(\n",
    "            'span').find('svg').find_next_sibling().text\n",
    "\n",
    "        record = {\n",
    "            'Title': title,\n",
    "            'Release_Year': int(releae_year),\n",
    "            'Length': length,\n",
    "            'Kind': kind,\n",
    "            'Rate': float(rate)\n",
    "        }\n",
    "\n",
    "        record = pd.DataFrame(record, index=[0])\n",
    "        df = pd.concat([df, record], ignore_index=True)\n",
    "\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we parsed the page into html tree, so we can search on our data.<br>\n",
    "After studying the html using inspect tool form the browser, now we could know how to search our needed data.<br>\n",
    "Then we stored the data into a dataframe, so we can manipulate it later and save it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This is the data looks like after extracing it form the web page"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| No | Title                                     | Release_Year | Length | Kind  | Rate |\n",
    "|----|-------------------------------------------|--------------|--------|-------|------|\n",
    "| 0  | 1. The Shawshank Redemption               | 1994         | 2h 22m | 18+   | 9.3  |\n",
    "| 1  | 2. The Godfather                         | 1972         | 2h 55m | PG-13 | 9.2  |\n",
    "| 2  | 3. The Dark Knight                       | 2008         | 2h 32m | 16+   | 9.0  |\n",
    "| 3  | 4. The Godfather Part II                  | 1974         | 3h 22m | PG-13 | 9.0  |\n",
    "| 4  | 5. 12 Angry Men                           | 1957         | 1h 36m | G     | 9.0  |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transform the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_data(df):\n",
    "    df['Title'] = df['Title'].apply(lambda x: x[x.find(' '):].strip())\n",
    "\n",
    "    length = df['Length'].str.split()\n",
    "    new_length = []\n",
    "    for l in length:\n",
    "        h = l[0][:-1]\n",
    "        m = l[1][:-1]\n",
    "        lon = time(hour=int(h), minute=int(m))\n",
    "        time_formate = '%H:%M'\n",
    "        l = time.strftime(lon, time_formate)\n",
    "        new_length.append(l)\n",
    "    new_length = pd.Series(new_length)\n",
    "    df['Length'] = new_length\n",
    "\n",
    "    rating = df['Kind']\n",
    "    new_rate = []\n",
    "    for r in rating:\n",
    "        if r == '13+':\n",
    "            r = 'PG-13'\n",
    "            new_rate.append(r)\n",
    "        elif r == '16+':\n",
    "            r = 'R'\n",
    "            new_rate.append(r)\n",
    "        elif r == '18+':\n",
    "            r = 'NC-17'\n",
    "            new_rate.append(r)\n",
    "        else:\n",
    "            new_rate.append(r)\n",
    "    new_rate = pd.Series(new_rate)\n",
    "    df['Kind'] = new_rate\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data is available now, but has some issues, so here we're gonna clean and transofrm it as we need.<br>\n",
    "- The title has extra numbering at the beginning that we don't need.\n",
    "- The length is formatted in different way, so we will reformat it as we want.\n",
    "- Some data in Kind column are represented in +age, we will change it to be represented as letters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### And this is the data after cleaning and transforming it"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| No | Title                     | Release_Year | Length | Kind  | Rate |\n",
    "|----|---------------------------|--------------|--------|-------|------|\n",
    "| 0  | The Shawshank Redemption  | 1994         | 02:22  | NC-17 | 9.3  |\n",
    "| 1  | The Godfather             | 1972         | 02:55  | PG-13 | 9.2  |\n",
    "| 2  | The Dark Knight           | 2008         | 02:32  | R     | 9.0  |\n",
    "| 3  | The Godfather Part II     | 1974         | 03:22  | PG-13 | 9.0  |\n",
    "| 4  | 12 Angry Men              | 1957         | 01:36  | G     | 9.0  |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_db(df, table, sql_db):\n",
    "    try:\n",
    "        conn = sqlite3.connect(sql_db)\n",
    "        df.to_sql(name=table, con=conn, if_exists='replace', index=True)\n",
    "        conn.commit()\n",
    "        conn.close()\n",
    "        return 'Data Saved in DB Successfuly'\n",
    "    except Exception as e:\n",
    "        return (f\"Error saving DB: {e}\")\n",
    "\n",
    "\n",
    "def load_json(df, to_json):\n",
    "    try:\n",
    "        df.to_json(to_json, orient='index')\n",
    "        return 'Data Saved in JSON Successfuly'\n",
    "    except Exception as e:\n",
    "        return (f\"Error saving JSON: {e}\")\n",
    "\n",
    "\n",
    "def load_csv(df, to_csv):\n",
    "    try:\n",
    "        df.to_csv(to_csv)\n",
    "        return 'Data Saved in CSV Successfuly'\n",
    "    except Exception as e:\n",
    "        return (f\"Error saving CSV: {e}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We saved the data in different files using pandas lib:<br>\n",
    "1. We start a sqlite3 connection to save the data in DB.\n",
    "2. We saved the data into a JSON file.\n",
    "3. We saved the data in CSV file."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Execute a query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Here are the result of Select All query from DB\n",
      "\n",
      "   index                     Title  Release_Year Length   Kind  Rate\n",
      "0      0  The Shawshank Redemption          1994  02:22  NC-17   9.3\n",
      "1      1             The Godfather          1972  02:55  PG-13   9.2\n",
      "2      2           The Dark Knight          2008  02:32      R   9.0\n",
      "3      3     The Godfather Part II          1974  03:22  PG-13   9.0\n",
      "4      4              12 Angry Men          1957  01:36      G   9.0\n"
     ]
    }
   ],
   "source": [
    "import sqlite3\n",
    "import pandas as pd\n",
    "\n",
    "def execute_sql_query(query_statement, param, sql_db):\n",
    "    try:\n",
    "        conn = sqlite3.connect(sql_db)\n",
    "        result = pd.read_sql(query_statement, params=param, con=conn)\n",
    "        conn.commit()\n",
    "        conn.close()\n",
    "        return result\n",
    "    except Exception as e:\n",
    "        return (f\"Error processing query: {e}\")\n",
    "\n",
    "\n",
    "sql_table = 'Best_movies'\n",
    "sql_db = 'Best_movies.db'\n",
    "query = (f'SELECT * FROM {sql_table} LIMIT ?')\n",
    "param = [5]\n",
    "result = execute_sql_query(query, param, sql_db)\n",
    "\n",
    "print('\\n\\nHere are the result of Select All query from DB\\n')\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we can execute any query on the DB and the result will be returned as a dataframe."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_progress(message, log_file):\n",
    "    with open(log_file, 'a') as f:\n",
    "        time_now = datetime.now()\n",
    "        date_formate = '%Y-%m-%d %A    %H:%M:%S'\n",
    "        date = time_now.strftime(date_formate)\n",
    "        f.write(message+'   '+date+'\\n')\n",
    "        return True\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Last thing, we will keep track of each process whether it's completed successfully or not with its timestamp in a text file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Author: Doaa Ali El-Sayed <a href='https://www.linkedin.com/in/doaa-ali-8097a3262/'>LinkedIn</a> <a href='https://github.com/DoaaAli11'>Github</a>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "vscode": {
   "interpreter": {
    "hash": "469512ab5cd0db3c29d19bbddd053d8f90dc7a1d92a52ff705a8063b0c47d0bd"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
